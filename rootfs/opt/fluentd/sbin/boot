#!/bin/bash
FLUENTD_CONF="/opt/fluentd/conf/fluentd.conf"
FLUENTD_FLUSH_INTERVAL=${FLUENTD_FLUSH_INTERVAL:-10s}
FLUENTD_FLUSH_THREADS=${FLUENTD_FLUSH_THREADS:-1}
FLUENTD_RETRY_LIMIT=${FLUENTD_RETRY_LIMIT:-10}
FLUENTD_DISABLE_RETRY_LIMIT=${FLUENTD_DISABLE_RETRY_LIMIT:-true}
FLUENTD_RETRY_WAIT=${FLUENTD_RETRY_WAIT:-1s}
FLUENTD_MAX_RETRY_WAIT=${FLUENTD_MAX_RETRY_WAIT:-60s}
FLUENTD_BUFFER_CHUNK_LIMIT=${FLUENTD_BUFFER_CHUNK_LIMIT:-8m}
FLUENTD_BUFFER_QUEUE_LIMIT=${FLUENTD_BUFFER_QUEUE_LIMIT:-8192}
FLUENTD_BUFFER_TYPE=${FLUENTD_BUFFER_TYPE:-memory}
FLUENTD_BUFFER_PATH=${FLUENTD_BUFFER_PATH:-/var/fluentd/buffer}

if [ -e "/var/log/containers" ]
then
cat << EOF >> $FLUENTD_CONF
<source>
  @type tail
  path /var/log/containers/*.log
  pos_file /var/log/containers.log.pos
  time_format %Y-%m-%dT%H:%M:%S.%NZ
  tag kubernetes.*
  format json
  read_from_head false
</source>

# Example:
# Dec 21 23:17:22 gke-foo-1-1-4b5cbd14-node-4eoj startupscript: Finished running startup script /var/run/google.startup.script
<source>
  type tail
  format syslog
  path /var/log/startupscript.log
  pos_file /var/log/startupscript.log.pos
  tag startupscript
</source>

# Examples:
# time="2016-02-04T06:51:03.053580605Z" level=info msg="GET /containers/json"
# time="2016-02-04T07:53:57.505612354Z" level=error msg="HTTP Error" err="No such image: -f" statusCode=404
<source>
  type tail
  format /^time="(?<time>[^)]*)" level=(?<severity>[^ ]*) msg="(?<message>[^"]*)"( err="(?<error>[^"]*)")?( statusCode=($<status_code>\d+))?/
  time_format %Y-%m-%dT%H:%M:%S.%NZ
  path /var/log/docker.log
  pos_file /var/log/docker.log.pos
  tag docker
</source>

# Example:
# 2016/02/04 06:52:38 filePurge: successfully removed file /var/etcd/data/member/wal/00000000000006d0-00000000010a23d1.wal
<source>
  type tail
  # Not parsing this, because it doesn't have anything particularly useful to
  # parse out of it (like severities).
  format none
  path /var/log/etcd.log
  pos_file /var/log/etcd.log.pos
  tag etcd
</source>

# Multi-line parsing is required for all the kube logs because very large log
# statements, such as those that include entire object bodies, get split into
# multiple lines by glog.

# Example:
# I0204 07:32:30.020537    3368 server.go:1048] POST /stats/container/: (13.972191ms) 200 [[Go-http-client/1.1] 10.244.1.3:40537]
<source>
  type tail
  format multiline
  format_firstline /^\w\d{4}/
  format1 /^(?<severity>\w)(?<time>\d{4} [^\s]*)\s+(?<pid>\d+)\s+(?<source>[^ \]]+)\] (?<message>.*)/
  time_format %m%d %H:%M:%S.%N
  path /var/log/kubelet.log
  pos_file /var/log/kubelet.log.pos
  tag kubelet
</source>

# Example:
# I0204 07:00:19.604280       5 handlers.go:131] GET /api/v1/nodes: (1.624207ms) 200 [[kube-controller-manager/v1.1.3 (linux/amd64) kubernetes/6a81b50] 127.0.0.1:38266]
<source>
  type tail
  format multiline
  format_firstline /^\w\d{4}/
  format1 /^(?<severity>\w)(?<time>\d{4} [^\s]*)\s+(?<pid>\d+)\s+(?<source>[^ \]]+)\] (?<message>.*)/
  time_format %m%d %H:%M:%S.%N
  path /var/log/kube-apiserver.log
  pos_file /var/log/kube-apiserver.log.pos
  tag kube-apiserver
</source>

# Example:
# I0204 06:55:31.872680       5 servicecontroller.go:277] LB already exists and doesn't need update for service kube-system/kube-ui
<source>
  type tail
  format multiline
  format_firstline /^\w\d{4}/
  format1 /^(?<severity>\w)(?<time>\d{4} [^\s]*)\s+(?<pid>\d+)\s+(?<source>[^ \]]+)\] (?<message>.*)/
  time_format %m%d %H:%M:%S.%N
  path /var/log/kube-controller-manager.log
  pos_file /var/log/kube-controller-manager.log.pos
  tag kube-controller-manager
</source>

# Example:
# W0204 06:49:18.239674       7 reflector.go:245] pkg/scheduler/factory/factory.go:193: watch of *api.Service ended with: 401: The event in requested index is outdated and cleared (the requested history has been cleared [2578313/2577886]) [2579312]
<source>
  type tail
  format multiline
  format_firstline /^\w\d{4}/
  format1 /^(?<severity>\w)(?<time>\d{4} [^\s]*)\s+(?<pid>\d+)\s+(?<source>[^ \]]+)\] (?<message>.*)/
  time_format %m%d %H:%M:%S.%N
  path /var/log/kube-scheduler.log
  pos_file /var/log/kube-scheduler.log.pos
  tag kube-scheduler
</source>
EOF
else
  echo "/var/log/containers does not exist in the container."
fi


if [ -n "$KUBERNETES_SERVICE_HOST" ]
then
cat << EOF >> $FLUENTD_CONF
  <filter kubernetes.**>
    @type kubernetes_metadata
    kubernetes_url https://${KUBERNETES_SERVICE_HOST}:${KUBERNETES_SERVICE_PORT}
    bearer_token_file /var/run/secrets/kubernetes.io/serviceaccount/token
    verify_ssl false
  </filter>
EOF
fi

cat << EOF >> $FLUENTD_CONF
<match **>
  @type copy
EOF

if [ -n "$ELASTICSEARCH_HOST" ]
then
  echo "Starting fluentd with elastic search configuration!"
  ELASTICSEARCH_PORT=${ELASTICSEARCH_PORT:-9200}
  ELASTICSEARCH_SCHEME=${ELASTICSEARCH_SCHEME:-http}

cat << EOF >> $FLUENTD_CONF
<store>
  @type elasticsearch
  log_level warn
  include_tag_key true
  time_key time
  host ${ELASTICSEARCH_HOST}
  port ${ELASTICSEARCH_PORT}
  scheme ${ELASTICSEARCH_SCHEME}
  $([ -n "${ELASTICSEARCH_USER}" ] && echo user ${ELASTICSEARCH_USER})
  $([ -n "${ELASTICSEARCH_PASSWORD}" ] && echo password ${ELASTICSEARCH_PASSWORD})
  buffer_type ${FLUENTD_BUFFER_TYPE}
  $([ "${FLUENTD_BUFFER_TYPE}" == "file" ] && echo buffer_path ${FLUENTD_BUFFER_PATH})
  buffer_chunk_limit ${FLUENTD_BUFFER_CHUNK_LIMIT}
  buffer_queue_limit ${FLUENTD_BUFFER_QUEUE_LIMIT}
  flush_interval ${FLUENTD_FLUSH_INTERVAL}
  retry_limit ${FLUENTD_RETRY_LIMIT}
  $([ "${FLUENTD_DISABLE_RETRY_LIMIT}" == "true" ] && echo disable_retry_limit)
  retry_wait ${FLUENTD_RETRY_WAIT}
  max_retry_wait ${FLUENTD_MAX_RETRY_WAIT}
  num_threads ${FLUENTD_FLUSH_THREADS}
</store>
EOF
fi

NUM=$(env | grep -oE '^(SYSLOG_HOST_\d*)' | wc -l)
for ((i=1; i<=$NUM; i++)) do
host=$(eval "echo \$SYSLOG_HOST_$i")
port=$(eval "echo \$SYSLOG_PORT_$i")
if [ -n "$host" ]
then
echo "Starting fluentd with syslog configuration! -- $host:$port"
cat << EOF >> $FLUENTD_CONF
<store>
  @type remote_syslog
  host $host
  port $port
  log_level warn
</store>
EOF
fi
done

if [ -n "$SYSLOG_HOST" ]
then
echo "Starting fluentd with syslog configuration! -- $SYSLOG_HOST:$SYSLOG_PORT"
cat << EOF >> $FLUENTD_CONF
<store>
  @type remote_syslog
  host $SYSLOG_HOST
  port $SYSLOG_PORT
  log_level warn
</store>
EOF
fi

if [ -n "$SUMOLOGIC_COLLECTOR_URL" ]
then
IS_HTTPS=`echo "$SUMOLOGIC_COLLECTOR_URL" | grep -c 'https://'`
SUMOLOGIC_HOST=`echo "$SUMOLOGIC_COLLECTOR_URL" | sed 's/https*:\/\///' | cut -d '/' -f 1`
SUMOLOGIC_ENDPOINT=`echo "$SUMOLOGIC_COLLECTOR_URL" | sed "s/.*:\/\/$SUMOLOGIC_HOST//"`

SUMOLOGIC_PORT=443
if [ $IS_HTTPS != 1 ]
then
  SUMOLOGIC_PORT=80
fi

cat << EOF >> $FLUENTD_CONF 
<store>
  buffer_type file
  buffer_path /var/log/fluent/logcentral
  type sumologic
  host $SUMOLOGIC_HOST
  port $SUMOLOGIC_PORT
  format json
  path $SUMOLOGIC_ENDPOINT
</store>
EOF
fi

cat << EOF >> $FLUENTD_CONF
<store>
  @type deis
</store>
</match>
EOF

exec fluentd -c $FLUENTD_CONF
